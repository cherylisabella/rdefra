---
title: "Response to reviewers"
author: "Claudia Vitolo"
date: "13 August 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## rdefra - response to reviewers (step 1)

Many thanks again for reviewing my package. Below are my responses to reviewers' comments.

### Reviewer 1 (@masalmon)

#### General

* Regarding the name of the package: In 2010 DEFRA launched their Open Data Strategy and mentioned the intention of opening up many environment-related datasets. I started working on the UK-AIR data archive but this is only one of the data sources available. In future releases of rdefra, I could use the same logic to get data from other DEFRA archives. owever, if based on best practice, `ukair` would be a more suitable name for the package, I am happy to change it.

* Spelling mistakes are now fixed. Please note that 'metres' is correct (as in metres above sea level)

* A code of conduct is now added to the package

* I modified the DESCRIPTION file and used the Authors@R syntax

* The DESCRIPTION, vignette and README files now include a link to UK air’s website.

* I have contacted DEFRA and informed them about the rdefra package.

#### Code

* Very good suggestion! All the names of the functions in rdefra  are now in lower case and have a prefix (ukair):
    * `catalogue()` is now called `ukair_catalogue()`
    * `EastingNorthing()` is now called `ukair_get_coordinates()`
    * `get1Hdata()` is now called `ukair_get_hourly_data()`
    * `getSiteID()` is now called `ukair_get_site_id()`

* I added some if statements to the functions to checks the validity of user's parameters.

* The date and time columns in the object returned by `ukair_get_hourly_data()` are now merged in the column datetime.

* Start.Date and End.Date in the `stations` object are now dates. 

* All the data frames returned by the rdefra functions are now tbl_df/tibble for better checking and printing capabilities

* Measurements are usually ugm-3 (micrograms per cubic metre), this is specified in the documentation of `ukair_get_hourly_data()`. However, I have added a new parameter called `keepUnits` that allows to retrieve the units for each observed variable.

* The `ukair_get_coordinates()` function now returns a data.frame, however it takes a long time to run it for the full catalogue. Therefore it is not convenient to generate a newly populated catalogue everytime we run this function. However I have cached a version of the catalogue and saved in as stations.rda (in the data folder). This contains all the coordinates and site identification numbers that can be retrieved using `ukair_get_coordinates()` and `ukair_site_id()` respectively.

* I fixed the problem with message/stop.

* Regarding the use of standard evaluation, I see your point, the code would be easier to read and probably runs faster. For the time being I would prefer not to include too many dependencies and stick with base R as much as possible. But for a future release I could run a benchmark using the two options and see which one works best for this package. 

* Yes, the cached version of stations include all the coordinates that can be retrieved using `ukair_get_coordinates()`.

#### Dependencies

* I have added testthat, raster, sp, leaflet, parallel to Suggests in the DESCRIPTION file

* I have replaced fuctions from the XML package with the corresponding functions from the xml2 package, as both you and @haozhu233 suggested.

* The package now uses httr in place of RCurl

* I replaced plyr::rbind.fill with dplyr::rbind_all

#### Readme and vignette

* ropenaq is now mentioned in the README file, along with openair. That was absolutely fair, sorry if I missed that before.

* In the README/vignette, I mentioned that data has been collected since 1972 and now added the most common species monitored and their typical units.

* The vignette has now the same title as the JOSS paper, I also fixed the typo (Rdefra vs rdefra).

* I set eval = FALSE for the installation instructions in the vignette

* Now the vignette builds quickly, as the map only contains stations in the Reading/Wokingham Urban Area.

* I added to the vignette in-line code so that the number of stations are automatically updated.

* I removed the spatial filter from the vignette.

* At the end of the vignette now is the code to retrieve data using multiple cores using the parallel package (with eval=FALSE).

* The filtered stations are now printed concisely with `as_tibble()`.

#### Documentation

* The NAMESPACE is now generated by roxygen2.

* The data documentation is now generated by roxygen2.

* I have added a top-level documentation for the rdefra-package.

* I have added and example in the `ukair_get_hourly_data()` documentation to show how to download data for multiple years.

* The documentation of `ukair_get_site_id()` now states that the ID can be found in the cached catalogue (stations.rda in the data folder).

* I have added to the documentation of stations (and the vignette) that the network is expected to expand over time.

* In the `ukair_catalogue()` function documentation, I added all the information I could find (scraping DEFRA web pages) about country numbers / region_id/pollutants/etc. Unfortunately there is no API and therefore no related documentation on the website.

* In the `ukair_catalogue()` function I removed the last three arguments because they are not important for the typical user of the package.

* Examples that shouldn’t be run are now packed in \dontrun{}

#### Tests

* Hadley Wickham (https://journal.r-project.org/archive/2011-1/RJournal_2011-1_Wickham.pdf) suggests that a 'context' should group tests for related functionality. In my interpretation, I thought I could group tests related to the type of retrieved output: data and metadata. For instance, in the first group I test the functions that generate metadata as well as the connections to the related webpage. In the second group I test the functions that generate data as well as the connections to the related files. Would this approach be considered unacceptable?

* I added a codecov.io badge to the rdefra repository?

* I have used `testthat::skip_on_cran` before the last metadata test.

### Reviewer 2 (@haozhu233)

* I have replaced fuctions from the XML package with the corresponding functions from the xml2 package, as both you and @masalmon suggested.

* Now I use a class as a locator to target the csv link in `ukair_catalogue()`, thanks for providing an example! However, I can't work out a similar approach for `ukair_get_coordinates_internal()` and `ukair_get_site_id_internal()`. What would you suggest to do in these cases?

* You are right, the fetching is very slow. For this reason there is a cached version of the catalogue in the package's data folder (stations.rda). I'm going to update it regularly.

* The functions now print a message when the csv/HTML page requested do not exist.

* sapply works much better than do.call+rbind+lapply, thanks!

* I replaced paste(sep="") with paste0().

* In `ukair_get_hourly_data()` I have created more checks to validate the inputs.

* In `ukair_get_hourly_data()` id is only using to fill in the `dat` object.

* In `ukair_get_hourly_data()`, I followed your suggeston to use the `try()` and a statement to check whether the csv can be downloaded.

* Now all the code lines are limited to 80 characters.

* The rdefra package now depends on lubridate, tibble, httr, xml2, dplyr. I did not use readr because read.csv was working better in my case.

* I now use roxygen2 to generate automatically the NAMESPACE

* I have put the tests in the root folder 

* Test cases are now in a statement format.

## rdefra - response to reviewers (step 2)

Thanks a lot for all your very constructive feedbacks and suggestions. I think this package has greatly improved since the first submission. Below are the responses to your latest comments, hope I did not forget anything. Thanks again and please let me know if there is anything else I could add/change.

### @masalmon

* I have replaced `dplyr::rbind_all` with `dplyr::bind_rows`. Thanks for spotting that, much appreciated! 

* I have added few more messages to `ukair_get_hourly_data()`, hope that will make error messages more informative.

* Well spotted! I added the timezone to lubridate calls.

* I have looked at lubridate errors and tried to sort the umbiguities. Now the only warnings that I get are related to non-existent dates (i.e. 2005.04.31), therefore I thought it is safe to suppress them. 

* I followed your suggestion to format the units in the documentation for `ukair_get_hourly_data` (wrapping the units in the \eqn command) but I cannot manage to remove the space between \mu and g/m^3 without getting a Latex error. I also liked the idea to have units as a separate table using something like `attr(output, "units") <- units`. Unfortunately the new attribute is not preserved when calling the function. Therefore I decided to output a list with two elements: 'data' and 'units'. Would that be ok? Finally, the status information informs the user on whether the  ratification checks and corrections have been made (ratified status).

* The `ukair_get_coordinates` now can be used inputting strings, a vector of strings or a data.frame. In the latter case, it infills missing longitude and latitude for a subset of stations in the catalogue.

#### Readme and vignette

* I have set eval = FALSE for the installation instructions in the README and vignette.

* I fixed the errors/warnings you got while compiling the vignette

#### Documentation

* I have added a new line between information for `pollutant` and `group_id`, and I also added bullet points for each parameter.

#### Tests

* Added some plots to README and vignette 

### @sckott 

* I have moved lubridate, tibble, httr, xml2, dplyr to Imports - Thanks for spotting that!

### @haozhu233

* I have tried using you xPath (page_tab <- xml2::xml_find_first(page_content, "//a[text()='Pre-Formatted Data Files']") but I get and empty node. I'll keep the original XPath but I'll periodically check that works.

* I now use @importFrom only in the rdefra-package.R file. Thanks, well spotted!

* I have changed the names of the variables in the README from stations and stationsNew to stations_raw and stations. I also added few plots.
